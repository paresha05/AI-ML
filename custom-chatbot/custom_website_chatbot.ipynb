{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom website chatbot\n",
        "https://www.utdallas.edu/sitemap.xml"
      ],
      "metadata": {
        "id": "yzqUREl5yE4Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZMmZ67DujUP"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain\n",
        "!pip -q install bitsandbytes accelerate transformers\n",
        "!pip -q install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install unstructured"
      ],
      "metadata": {
        "id": "be2a8end0rgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client==2.2.4"
      ],
      "metadata": {
        "id": "guBYVWoa1Lrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone\n",
        "import pinecone\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "from langchain import HuggingFacePipeline\n",
        "from huggingface_hub import notebook_login\n",
        "import torch"
      ],
      "metadata": {
        "id": "LT2c3xXD0rd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract data from url"
      ],
      "metadata": {
        "id": "pnVaHL3m1jo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4"
      ],
      "metadata": {
        "id": "9NrCBV6z2Rsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URLs = [\n",
        "    \"https://www.utdallas.edu/\"\n",
        "]"
      ],
      "metadata": {
        "id": "xsWfuDYi1gnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UnstructuredURLLoader(urls = URLs)\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "VjA3XTze1glM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "e1hFR_3c1gij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunkins"
      ],
      "metadata": {
        "id": "rYaKMbAy2x9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=CharacterTextSplitter(separator='\\n',\n",
        "                                    chunk_size=1000,\n",
        "                                    chunk_overlap=200)"
      ],
      "metadata": {
        "id": "NaX8iHJo1ggD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks=text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "FwQPm5kI1gcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "id": "pRjOlOnn1gaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0]"
      ],
      "metadata": {
        "id": "Mf-d7fWP28rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding model"
      ],
      "metadata": {
        "id": "z4Faxi8B3ZUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "PWxopISM2-Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = embeddings.embed_query(\"Hello world\")\n",
        "len(query_result)"
      ],
      "metadata": {
        "id": "yCBfTFnm3kMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result"
      ],
      "metadata": {
        "id": "xzG_YgHB5BSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', '6ee7dc8a-43fb-4480-8774-f1d02577386d')\n",
        "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')"
      ],
      "metadata": {
        "id": "QtPzGrEr3kKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_API_ENV  # next to api key in console\n",
        ")\n",
        "index_name = \"website-bot\" # put in the name of your pinecone index here\n"
      ],
      "metadata": {
        "id": "taQStmiG3kHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "T_RZ5krD3kFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create LLM wrapper"
      ],
      "metadata": {
        "id": "ImhSrake5oLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "8606M1rO3kCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "                                          use_auth_token=True,)\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "                                             device_map='auto',\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             use_auth_token=True,\n",
        "                                              load_in_8bit=True,\n",
        "                                              #load_in_4bit=True\n",
        "                                             )"
      ],
      "metadata": {
        "id": "gJGCM1ak5rTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = transformers.pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer= tokenizer,\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                device_map=\"auto\",\n",
        "                max_new_tokens = 512,\n",
        "                do_sample=True,\n",
        "                top_k=30,\n",
        "                num_return_sequences=1,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "                )"
      ],
      "metadata": {
        "id": "yogGHA3F6tLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})"
      ],
      "metadata": {
        "id": "Yse04NpL6tGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"Please provide a concise summary of the Book Harry Potter\")"
      ],
      "metadata": {
        "id": "4peIRKSe6tEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the Retrieval QA"
      ],
      "metadata": {
        "id": "5ON967Wz8Qxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "86x-Di-76tBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "n0aSWeGC6s-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me the course price of Full Stack Data Science with Generative AI provide by ineuron\"\n"
      ],
      "metadata": {
        "id": "sCtFS0zS8W9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa.run(query))"
      ],
      "metadata": {
        "id": "l8E656pa8W7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}